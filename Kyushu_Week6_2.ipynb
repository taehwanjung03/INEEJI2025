{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2b17d5-781d-428f-8014-30fd4e4663b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with more than half NaN dropped. Remaining rows: 2811\n",
      "Removed 4 rows where 사용전력량 < 15000.\n",
      "\n",
      "--- XGBoost Model Evaluation ---\n",
      "XGBoost Train Scores:\n",
      "  MSE:  0.00\n",
      "  RMSE: 0.00\n",
      "  MAE:  0.00\n",
      "  MAPE: 0.00%\n",
      "  R²:   1.000\n",
      "\n",
      "XGBoost Test Scores:\n",
      "  MSE:  220898.16\n",
      "  RMSE: 470.00\n",
      "  MAE:  470.00\n",
      "  MAPE: 2.47%\n",
      "  R²:   0.000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[39m, in \u001b[36m_iLocIndexer._get_list_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4172\u001b[39m, in \u001b[36mNDFrame._take_with_is_copy\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4163\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4164\u001b[39m \u001b[33;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[32m   4165\u001b[39m \u001b[33;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4170\u001b[39m \u001b[33;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[32m   4171\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4172\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4173\u001b[39m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4152\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4148\u001b[39m     indices = np.arange(\n\u001b[32m   4149\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4150\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4152\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4154\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4158\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4159\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:891\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    890\u001b[39m n = \u001b[38;5;28mself\u001b[39m.shape[axis]\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m indexer = \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[39m, in \u001b[36mmaybe_convert_indices\u001b[39m\u001b[34m(indices, n, verify)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mindices are out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[31mIndexError\u001b[39m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 169\u001b[39m\n\u001b[32m    167\u001b[39m model = XGBRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m    168\u001b[39m model.fit(X_train, y_train)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mXGBoost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepair_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(name, model, X_train, y_train, X_test, y_test, df)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Use dates from the already filtered repair_df\u001b[39;00m\n\u001b[32m    127\u001b[39m repair_dates_df = repair_df[[\u001b[33m'\u001b[39m\u001b[33m날짜\u001b[39m\u001b[33m'\u001b[39m]].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m train_df = \u001b[43mrepair_dates_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m    130\u001b[39m train_df[\u001b[33m'\u001b[39m\u001b[33mActual\u001b[39m\u001b[33m'\u001b[39m] = y_train.values\n\u001b[32m    131\u001b[39m train_df[\u001b[33m'\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m'\u001b[39m] = train_pred\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1743\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1747\u001b[39m     key = item_from_zerodim(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1717\u001b[39m, in \u001b[36m_iLocIndexer._get_list_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1714\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._take_with_is_copy(key, axis=axis)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpositional indexers are out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# Suppress warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import shap\n",
    "\n",
    "# Set font for plots\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv('C:/Users/User/Downloads/Kyushu Datasheets/data_with_press_and_weather.csv', low_memory=False)\n",
    "\n",
    "# Drop rows with excessive missing values\n",
    "missing_count = df.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    threshold = df.shape[1] // 2\n",
    "    df = df.dropna(thresh=threshold + 1)\n",
    "    print(f\"Rows with more than half NaN dropped. Remaining rows: {len(df)}\")\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "\n",
    "# Target variable\n",
    "target = '사용전력량'\n",
    "\n",
    "# Clean and filter '강번'\n",
    "df['강번'] = pd.to_numeric(df['강번'], errors='coerce')\n",
    "df = df.dropna(subset=['강번'])\n",
    "df = df[df['강번'].between(9000, 500000000)]\n",
    "\n",
    "# Outlier removal\n",
    "if target in df.columns:\n",
    "    initial_count_oxygen = len(df)\n",
    "    df = df[df[target] >= 15000]\n",
    "    removed_count_oxygen = initial_count_oxygen - len(df)\n",
    "    print(f\"Removed {removed_count_oxygen} rows where {target} < 15000.\")\n",
    "else:\n",
    "    print(f\"Warning: '{target}' column not found.\")\n",
    "\n",
    "# Optional export for inspection\n",
    "df.to_csv('For_my_use_1.csv', index=False)\n",
    "\n",
    "# Feature engineering\n",
    "df['slag time'] = df['소요시간_추가1'] + df['소요시간_추가2'] + df['소요시간_산화'] + df['소요시간_환원']\n",
    "df['slag rate'] = df['CaO'] / 0.24 / df['slag time']\n",
    "\n",
    "variables = ['slag rate', 'WindSpeed_Avg (m/s)', 'WindSpeed_Max (m/s)', '소요시간_로 보수/수리',\n",
    "             '소요시간_주요장입', 'Precipitation (mm)', '연회회수', 'Temperature (°C)']\n",
    "\n",
    "# --- Define manual repair dates ---\n",
    "repair_dates = ['2024-02-01', '2024-03-12', '2024-04-25']  # Example\n",
    "repair_dates = pd.to_datetime(repair_dates)\n",
    "\n",
    "# --- Convert to datetime ---\n",
    "df['날짜'] = pd.to_datetime(df['날짜'], errors='coerce')\n",
    "\n",
    "# --- Get repair rows ---\n",
    "repair_df = df[df['날짜'].isin(repair_dates)].copy()\n",
    "\n",
    "# --- Prediction offset ---\n",
    "N = 3\n",
    "repair_df['target_date'] = repair_df['날짜'] + pd.Timedelta(days=N)\n",
    "\n",
    "# --- Fetch target usage ---\n",
    "df_by_date = df.set_index('날짜')\n",
    "df_by_date = df_by_date[~df_by_date.index.duplicated(keep='first')]\n",
    "repair_df['target_usage'] = repair_df['target_date'].map(df_by_date['사용전력량'])\n",
    "repair_df = repair_df.dropna(subset=['target_usage'])\n",
    "\n",
    "# --- Final dataset ---\n",
    "X = repair_df[variables].fillna(0)\n",
    "y = repair_df['target_usage']\n",
    "\n",
    "# --- Split ---\n",
    "split_index = int(len(X) * 0.7)\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "# --- Evaluation ---\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, df):\n",
    "    print(f\"\\n--- {name} Model Evaluation ---\")\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, train_pred)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mae_train = mean_absolute_error(y_train, train_pred)\n",
    "    mape_train = np.mean(np.abs((y_train - train_pred) / y_train)) * 100\n",
    "    r2_train = r2_score(y_train, train_pred)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, test_pred)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_test = mean_absolute_error(y_test, test_pred)\n",
    "    mape_test = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
    "    r2_test = r2_score(y_test, test_pred)\n",
    "\n",
    "    print(f\"{name} Train Scores:\")\n",
    "    print(f\"  MSE:  {mse_train:.2f}\")\n",
    "    print(f\"  RMSE: {rmse_train:.2f}\")\n",
    "    print(f\"  MAE:  {mae_train:.2f}\")\n",
    "    print(f\"  MAPE: {mape_train:.2f}%\")\n",
    "    print(f\"  R²:   {r2_train:.3f}\")\n",
    "\n",
    "    print(f\"\\n{name} Test Scores:\")\n",
    "    print(f\"  MSE:  {mse_test:.2f}\")\n",
    "    print(f\"  RMSE: {rmse_test:.2f}\")\n",
    "    print(f\"  MAE:  {mae_test:.2f}\")\n",
    "    print(f\"  MAPE: {mape_test:.2f}%\")\n",
    "    print(f\"  R²:   {r2_test:.3f}\")\n",
    "\n",
    "    # Use dates from the already filtered repair_df\n",
    "    repair_dates_df = repair_df[['날짜']].reset_index(drop=True)\n",
    "    \n",
    "    train_df = repair_dates_df.iloc[X_train.index].copy()\n",
    "    train_df['Actual'] = y_train.values\n",
    "    train_df['Predicted'] = train_pred\n",
    "    train_df['Set'] = 'Train'\n",
    "    \n",
    "    test_df = repair_dates_df.iloc[X_test.index].copy()\n",
    "    test_df['Actual'] = y_test.values\n",
    "    test_df['Predicted'] = test_pred\n",
    "    test_df['Set'] = 'Test'\n",
    "\n",
    "    combined_df = pd.concat([train_df, test_df]).sort_values('날짜').reset_index(drop=True)\n",
    "    combined_df['Time Index'] = range(len(combined_df))\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.plot(combined_df['Time Index'], combined_df['Actual'], label='Actual', linewidth=2)\n",
    "    plt.plot(combined_df['Time Index'], combined_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "    test_start = combined_df[combined_df['Set'] == 'Test']['Time Index'].min()\n",
    "    plt.axvline(x=test_start, color='red', linestyle=':', label='Test Start')\n",
    "    plt.xlabel('Time Index (chronological)')\n",
    "    plt.ylabel(target)\n",
    "    plt.title(f'Actual vs Predicted {target} ({name}) - R² = {r2_test:.3f}, RMSE = {rmse_test:.1f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    test_df = test_df.sort_values('날짜').reset_index(drop=True)\n",
    "    test_df['Time Index'] = range(len(test_df))\n",
    "\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    plt.plot(test_df['Time Index'], test_df['Actual'], label='Actual', linewidth=2)\n",
    "    plt.plot(test_df['Time Index'], test_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Train and Evaluate ---\n",
    "model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model('XGBoost', model, X_train, y_train, X_test, y_test, repair_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cea4c-8448-4610-9783-e8ba3e2d1ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
