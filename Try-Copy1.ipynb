{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5091a290-eb26-493e-8a70-c9b77b67daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "import math\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import partial_dependence\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Set font before plotting\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2294847-b207-44d1-bf21-5eb7bf5d5415",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a912980-c1d5-42fc-8df6-f5af3300d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with more than half NaN dropped. Remaining rows: 2811\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV\n",
    "df = pd.read_csv('C:/Users/User/Downloads/Kyushu Datasheets/data_with_press_and_weather.csv', low_memory=False)\n",
    "\n",
    "# Check and remove rows with missing (NaN) values\n",
    "missing_count = df.isnull().sum().sum()\n",
    "\n",
    "if missing_count > 0:\n",
    "    threshold = df.shape[1] // 2\n",
    "    df = df.dropna(thresh=threshold + 1)\n",
    "    print(f\"Rows with more than half NaN dropped. Remaining rows: {len(df)}\")\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfef7556-0848-4dd7-a14e-53ec1903f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CC_P'\n",
    "\n",
    "# Convert to numeric, drop rows that couldn't be converted (20240101-1)\n",
    "df['강번'] = pd.to_numeric(df['강번'], errors='coerce')\n",
    "df = df.dropna(subset=['강번'])\n",
    "df = df[df['A부스러기\\u3000친'].notna()]\n",
    "df = df[df['와셔 친'].notna()]\n",
    "\n",
    "# Removes SC410 entries\n",
    "lower_bound = 9000\n",
    "upper_bound = 500000000\n",
    "\n",
    "# Apply filter\n",
    "df = df[df['강번'].between(9000, 500000000)]\n",
    "'''\n",
    "# Outlier removal\n",
    "if target in df.columns:\n",
    "    initial_count_oxygen = len(df)\n",
    "    df = df[df[target] >= 15000]\n",
    "    removed_count_oxygen = initial_count_oxygen - len(df)\n",
    "    print(f\"Removed {removed_count_oxygen} rows where {target} < 15000.\")\n",
    "else:\n",
    "    print(f\"Warning: '{target}' column not found.\")\n",
    "\n",
    "if 'Precipitation (mm)' in df.columns:\n",
    "    initial_count_oxygen = len(df)\n",
    "    df = df[df['Precipitation (mm)'] <= 10]\n",
    "    removed_count_oxygen = initial_count_oxygen - len(df)\n",
    "    print(f\"Removed {removed_count_oxygen} rows where 'Precipitation (mm)' > 05.\")\n",
    "else:\n",
    "    print(f\"Precipitation (mm)' column not found.\")\n",
    "\n",
    "'''\n",
    "\n",
    "df = df[df['연회회수'] != 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ad899e-2ad8-45d8-8438-7693f8432585",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "variables = [v for v in variables if '_P' not in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4328c6c4-6c55-487f-9c8b-796d19df7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[variables]\n",
    "y = df[target]\n",
    "\n",
    "# Sequential split (first 70% for training, last 30% for testing)\n",
    "split_index = int(len(X) * 0.7)\n",
    "X_train = X.iloc[:split_index].fillna(0)\n",
    "X_test = X.iloc[split_index:].fillna(0)\n",
    "y_train = y.iloc[:split_index]\n",
    "y_test = y.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be69a7-c528-4df1-b312-221705ce847e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7552e3-94e8-4628-acf3-873fb49648e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Linear Regression model\u001b[39;00m\n\u001b[32m      2\u001b[39m model = LinearRegression()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:618\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    614\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    616\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dacec24-3804-4c67-8f98-8d01dea240b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Actual vs Predicted Power Consumption Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel(f'Actual {target}')\n",
    "plt.ylabel(f'Predicted {target}')\n",
    "plt.title(f'MLR: Predicted vs. Actual {target}')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "rmse = np.sqrt(MSE)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"\\nIntercept:\", model.intercept_)\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X.columns, model.coef_):\n",
    "    print(f\"  {feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348626c-accf-4ad0-90bd-abc67dc38ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "feature_means = X_test.mean()\n",
    "\n",
    "# Subplots\n",
    "n_vars = len(variables)\n",
    "cols = 2\n",
    "rows = math.ceil(n_vars / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 5 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Generate plots\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i]\n",
    "    x_vals = np.linspace(X_test[var].min(), X_test[var].max(), 100)\n",
    "    y_vals = np.full_like(x_vals, model.intercept_, dtype=float)\n",
    "    for j, col in enumerate(X_test.columns):\n",
    "        if col == var:\n",
    "            y_vals += model.coef_[j] * x_vals  # vary only current variable\n",
    "        else:\n",
    "            y_vals += model.coef_[j] * feature_means[col]  # fix others at mean\n",
    "\n",
    "    # Scatter actual vs predicted\n",
    "    ax.scatter(X_test[var], y_test, alpha=1, label='Actual')\n",
    "    ax.plot(x_vals, y_vals, color='red', label='MLR Line')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel(f'{target}')\n",
    "    ax.set_title(f'{target} vs {var}')\n",
    "    ax.legend()\n",
    "\n",
    "# Remove any unused axes (if total axes > variable count)\n",
    "for j in range(n_vars, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('MLR Prediction vs Key Features', fontsize=16, y=1.03)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0df23-7096-42bd-bd23-fa330cb7b520",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Time Series Data MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1f873-c7d2-4a95-a7ba-854cd31d2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ID number, Actual power, and Predicted power into one DataFrame\n",
    "id_aligned_df = df[['강번']].loc[X_test.index].copy()\n",
    "id_aligned_df['Actual'] = y_test.values\n",
    "id_aligned_df['Predicted'] = y_pred\n",
    "\n",
    "# Sort by ID number for line plotting\n",
    "id_aligned_df = id_aligned_df.sort_values('강번').reset_index(drop=True)\n",
    "\n",
    "# Extract month from ID (e.g., 2401xxx → 1)\n",
    "id_aligned_df['Month'] = id_aligned_df['강번'].astype(str).str[2:4].astype(int)\n",
    "months = [10, 11, 12]\n",
    "\n",
    "# Set up subplots\n",
    "n_months = len(months)\n",
    "fig, axes = plt.subplots(n_months, 1, figsize=(12, 4 * n_months), sharey=True)\n",
    "\n",
    "if n_months == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, month in enumerate(months):\n",
    "    ax = axes[i]\n",
    "    month_df = id_aligned_df[id_aligned_df['Month'] == month].sort_values('강번')\n",
    "\n",
    "    ax.plot(month_df['강번'], month_df['Actual'], label='Actual', linewidth=2)\n",
    "    ax.plot(month_df['강번'], month_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "    ax.set_title(f'Month: {month} (ID starts with 24{month:02d})')\n",
    "    ax.set_xlabel('강번')\n",
    "    ax.set_ylabel(f'{target}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Predicted vs Actual {target} by Month', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3b4a6-5ef5-42c2-bc34-0ea462687d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous time index\n",
    "id_aligned_df['Time Index'] = range(len(id_aligned_df))\n",
    "\n",
    "# Plot with continuous index\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(id_aligned_df['Time Index'], id_aligned_df['Actual'], label='Actual', linewidth=2)\n",
    "plt.plot(id_aligned_df['Time Index'], id_aligned_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Time Index (chronological)')\n",
    "plt.ylabel('사용전력량')\n",
    "plt.title('Actual vs Predicted 사용전력량 Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4a412-267d-4d18-a6ae-0a2225483581",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fc55d-59c0-474d-b8c1-280ea25aa77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model set up\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.005,\n",
    "    max_depth= 4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ce8de-ee47-423c-a781-ccd3d6a72fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Actual vs Predicted Power Consumption Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_test, y=xgb_pred)\n",
    "plt.xlabel(f'Actual {target}')\n",
    "plt.ylabel(f'Predicted {target} (XGBoost)')\n",
    "plt.title(f'XGBoost: Predicted vs Actual {target}')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.legend(['Ideal'])\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n--- XGBoost Model Evaluation ---\")\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "print(\"XGBoost RMSE:\", rmse_xgb)\n",
    "print(\"R² Score:\", r2_score(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30214c34-c9d8-4aa7-a36e-c5fa8401bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Features to plot\n",
    "features = variables\n",
    "n_features = len(features)\n",
    "\n",
    "X_test = X_test.astype('float')\n",
    "\n",
    "# Adjust grid size based on number of features\n",
    "rows = (n_features + 1) // 2 \n",
    "fig, axes = plt.subplots(rows, 2, figsize=(16, rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the features\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    feature_index = X_test.columns.get_loc(feature)\n",
    "\n",
    "    # Partial dependence\n",
    "    pd_result = partial_dependence(xgb_model, X_test, [feature_index], kind='average')\n",
    "    x_vals = pd_result['grid_values'][0]\n",
    "    y_vals = pd_result['average'][0]\n",
    "\n",
    "    # Scatter: actual model predictions\n",
    "    sns.scatterplot(\n",
    "        x=X_test[feature],\n",
    "        y=xgb_model.predict(X_test),\n",
    "        alpha=1,\n",
    "        ax=ax,\n",
    "        label='Predicted'\n",
    "    )\n",
    "\n",
    "    # Partial dependence line\n",
    "    ax.plot(x_vals, y_vals, color='red', linewidth=2, label='Partial Dependence')\n",
    "\n",
    "    # Format\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(f'{target}')\n",
    "    ax.set_title(f'{target} vs {feature}')\n",
    "    ax.legend()\n",
    "\n",
    "# Remove unused axes\n",
    "for j in range(n_features, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "fig.suptitle(f'{target} vs Features with Partial Dependence (XGBoost)', fontsize=16)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24dfcd4-ed44-4398-aa1f-5f56bbd95311",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "for var, imp in sorted(zip(X.columns, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{var}: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7333078-7f54-4a7b-a9ab-8ec568b2a9cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Time Series Data XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dee59-678d-4f56-8673-e4cc0003c682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine ID number, Actual power, and Predicted power into one DataFrame\n",
    "id_aligned_df = df[['강번']].loc[X_test.index].copy()\n",
    "id_aligned_df['Actual'] = y_test.values\n",
    "id_aligned_df['Predicted'] = xgb_pred\n",
    "\n",
    "# Sort by ID number for line plotting\n",
    "id_aligned_df = id_aligned_df.sort_values('강번').reset_index(drop=True)\n",
    "\n",
    "# Extract month from ID (e.g., 2401xxx → 1)\n",
    "id_aligned_df['Month'] = id_aligned_df['강번'].astype(str).str[2:4].astype(int)\n",
    "months = [10, 11, 12]\n",
    "\n",
    "# Set up subplots\n",
    "n_months = len(months)\n",
    "fig, axes = plt.subplots(n_months, 1, figsize=(12, 4 * n_months), sharey=True)\n",
    "\n",
    "if n_months == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, month in enumerate(months):\n",
    "    ax = axes[i]\n",
    "    month_df = id_aligned_df[id_aligned_df['Month'] == month].sort_values('강번')\n",
    "\n",
    "    ax.plot(month_df['강번'], month_df['Actual'], label='Actual', linewidth=2)\n",
    "    ax.plot(month_df['강번'], month_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "    ax.set_title(f'Month: {month} (ID starts with 24{month:02d})')\n",
    "    ax.set_xlabel('강번')\n",
    "    ax.set_ylabel(f'{target}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Predicted vs Actual {target} by Month', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78d303-122c-42c9-883f-af95e6ec51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous time index\n",
    "id_aligned_df['Time Index'] = range(len(id_aligned_df))\n",
    "\n",
    "# Plot with continuous index\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(id_aligned_df['Time Index'], id_aligned_df['Actual'], label='Actual', linewidth=2)\n",
    "plt.plot(id_aligned_df['Time Index'], id_aligned_df['Predicted'], label='Predicted', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Time Index (chronological)')\n",
    "plt.ylabel('사용전력량')\n",
    "plt.title('Actual vs Predicted 사용전력량 Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c7168-c02f-4dee-8353-b2d4b4057a99",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b750e-04b6-407e-8699-4eb45164530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
